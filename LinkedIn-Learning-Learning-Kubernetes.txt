LinkedIn-Learning-Learning-Kubernetes

What is containerization?
A collection of software processes unified by one namespace, with access to an operating system kernel that it share with other containers and little to no access between containers. 

Docker Instance
A runtime instance of a Docker image contains three things:

1. A Docker image
2. An execution environment 
3. A standard set of instructions

Compared to object oriented programming a container would be an object, and a class would be the container. 

Docker Engine
-Comprised of the runtime and packaging tool
-Must be installed on the hosts that run Docker

Core elements of Docker
1) Docker Store
-An online cloud service where users can store and share their Docker images
-Also known as Docker Hub

2) Docker Store
-An online cloud service where users can store and share their Docker images
-Also known as Docker Hub

Virtual Machine (VM)
-One or many applications
-The necessary binaries and libraries
-The entire guest operating system to interact with the applications

Containers
-Include the application and all of its dependencies
-Share the kernel with other containers
-Not tied to infrastructure-only needs Docker Engine installed on the host
-Run as an isolated process in the user space on the host OS

Container Benefits for Developers

Applications are
1. Portable
2. Packaged in a standard way

Deployment is
1. Easy
2. Repeatable

Container Benefits for Developers
-Automated testing, packaging, and integrations
-Support newer microservice architectures
-Alleviate platform compatibility issues

Container Benefits for DevOps
-Reliable deployments: improve speed and frequency of releases
-Consistent application lifecycle: configure once and run multiple times

Container Benefits for DevOps
Consistent environments
-No more process difference between non-prod and production environments

Simple scaling
-Fast deployments ease the addition of workers and permit workload to grow and shrink for on-demand use cases

Developers and DevOps can come together as containers create a common language.

The DevOps team can isolate and debug issues at the container level. 

Use of Containerized Apps is on the Rise

Organizations will use containers more often. 

Containers and Microservices 

Allow the Building of Pipelines
-Containers bring agility to your code
-Help build a continuous integration and deployment pipeline
-Push an IT team to develop, test, and deploy applications faster
-Reason why enterprises have started to adopt containers in such a big way

Kubernetes - most popular open-source container orchestrator today

How do you manage all these containers running on a single host, and across your whole infrastructure?
Container orchestration!

Orchestrator Features
-Provision hosts
-Instantiation containers on a host
-Restart failing containers
-Have ability to link containers together so they can communicate with their peers
-Expose containers as a service outside of the cluster
-Scale the cluster up or down

Kubernetes (K8s)
-Definition: an open-source platform designed to automate deploying, scaling, and operating applications containers
-Goal: to foster an ecosystem of components and tools that relieve the burden of running applications in public and private clouds

Borg was the predecessor of Kubernetes (Google).

Kubernetes is a platform to schedule and run containers on clusters of virtual machines. It runs on bare metal, virtual machines, private datacenter and public cloud.

No golden handcuffs when migrating to the cloud.

Kubernetes and Docker

Kubernetes is a container platform. 

You can use Docker containers to develop and build applications, and then use Kubernetes to run these applications on your infrastructure.

There are other types of containers and many different companies using kubernetes

Kubernetes Features

"Kubernetes is an open source project that enables software teams of all sizes, from a small startup to a Fortune 100 company, to automate deploying, scaling, and managing applications on a group of cluster of server machines. These applications can include everything from internal-facing web applications like a content management system to marquee web properties like Gmail to big data processing."
-Joe Beda (One of the original developers who worked on Kubernetes)

Multi-Host Container Scheduling
-Done by the kube-scheduler
-Assigns pods to nodes at runtime
-Checks resources, quality of service, policies, and user specifications before scheduling

Scalability and Availability
-Kubernetes master can be deployed in a highly available configuration
-Multi-region deployments available 

Scalability (v.1.17)
-Supports 5k node clusters
-150k total pods
-Maximum of 100 pods per node
-Pods can be horizontally scaled via API

Flexibility and Modularization
-Plug-and-play architecture
-Extend architecture when needed
-Add-ons: network drivers, service discovery, container runtime, visualization, and command

Registration - Seamless nodes register themselves with master.
Service Discovery - Automatic detection of service and endpoints via DNS or Environment Variables

Persistent Storage
-Much requested and important feature when working with containers
-Pods can use persistent volumes to stores data
-Data retained across pod restarts and crashes

Application Upgrades and Downgrades
-Upgrades: rolling updates supported
-Downgrades: rollbacks are supported 

Maintenance
-Features are backward compatible
-APIs are versioned
-Turn off/on host during maintenance (unscheduled)

Logging and Monitoring
-Application monitoring built-in
--TCP, HTTP, or container execution health check
-Node health check
--Failures monitored by node controller
-Kubernetes status can also be monitored by:
--Add-ons: Heapster and cAdvisor
-Logging framework
--In place of extensible

Secrets Managed
-Sensitive data is a first-class citizen
-Mounted as data volumes or environment variables
-Specific to namespace

Community - one of the strongest open-source communities out there

There is a great amount of important documentation

-KubeCon - events.linuxfoundation.org
-Meetups - meetup.com/topics/kubernetes
-Slack - kubernetes.slack.com --great place to ask questions

Other Implementations

ADVICE - Don't build your own orchestrator today-you'll only regret it and end up moving to something else anyway. 

Major Players in Container Orchestration
-Kubernetes
-Docker Swarm
-Rancher
-Mesos

Cloud-Specific Technologies
-Amazon EC2 Container Service and Google Anthos

Mesos
-Written in C++, APIs in Java, C++, Python
-Oldest, most stable tool
-Distributed kernel
-Marathon framework to schedule and execute tasks
-More complicated architecture than Swarm

Typical Mesos Users
-Larger enterprises
-Projects that require lots of compute (big data jobs) or task-oriented workloads
-Driven by developers
-Need an ops team to manage

Rancher
-Full stack container management platform
-Install and manage Kubernetes clusters
-Early Docker ecosystem player
-Great user interface and API to interact with clusters
-Enterprise support

Typical Rancher Users
-Small teams to enterprises
-Support organizations and teams out of the box
-Nice user interface, and APIs
-Easy to manage infrastructure effectively

Guidelines for the Right Orchestrator for the Job:

Smaller team size & Number of Hosts/Containers to larger: Nomad, Rancher, Docker Swarm, Mesos, Kubernetes

Containers are the new normal, and many organizations are using them for production. 

When to Go Serverless
-Consider serverless technologies if:
--Starting to build your infrastructure form scratch
--Running your infrastructure in the cloud

Chapter Quiz
1)
Two features that allow Kubernetes Clusters to scale are -registration and -discovery.

2)
How would you best describe Kubernetes?
-an open-source platform designed to automate deploying, scaling, and operating application containers

3)
Why do organizations user containers?
-to build applications to incorporate a microservices-based architecture. 

The Kubernetes Architecture
Master Node -responsible for overall management of the Kubernetes cluster

3 components of the Master Node that take care communication, scheduling, and controllers:
1) The API Server -Front end of K8s control plane
2) Scheduler -Watches created Pods who do not have a Node design and design pods to run on a specific Node
3) Controller Manager 
3a) Node Controller - responsible for worker states
3b) Replication Controller - responsible for maintaining the correct number of Pods for the replicated controllers
3c) Endpoint controller -joins services and pods together. Service account and token controllers handle access management.

etcd - simple distributed key-value store

Kubernetes uses etcd as it's database, and stores all cluster data there. Information you might see in etcd is scheduling information, pod details, state information, etc.

You interact with the master node with kubectl. It has a configuration file called kubeconfig that has server information and authentication information to access the API server. 

Worker Node - where your application operates
-Communication to worker nodes are handled by the kubelet process

Kubelet process -agent that communicates with the API server to see if pods have been designed to the nodes. It executes pod containers via the container engine, mounts/runs pod volumes and secrets, and is aware of pod/node states and will respond back to the master. 

If kubelet isn't working correctly in the worker node, then you will have issues. 

Kubernetes is a container orchestration platform, so the expectation is that you have a container native platform running on your worker nodes. Docker comes into play because it works together with kubelet to run containers on the node -other platforms can be used but it's not common. 

Kube-proxy -network, proxy, and load balancer for the service on a single worker node. 
-Handles network routing for TCP and UDP packers and performs connection forwarding

Docker daemon allows you to run containers
Containers of an application are tightly coupled together in a pod

Pod -smallest unit that can be scheduled as deployment in kubernetes.

A group of containers can share storage, Linux namespace, IP addresses, amongst other things. They also co-located, and can also share resources that are scheduled together. Once a pod has been deployed and is running, the kubelet communicates with it to check its state and health. Kube-proxy routes any packets to the pods from other resources that might be wanting to communicate with them. Worker nodes can be exposed to the internet via the load balancer. Traffic coming to the nodes is handled by the Kube-proxy, which is how and end-user talks to a kubernetes application. 

Basic Building Blocks:
Nodes and Pods

From a cluster perspective, the master node is responsible for managing the cluster. It coordinates activities in the cluster and communicates with the nodes to keep kubernetes and the worker node applications running.

Node
The node serves as a worker machine in a K8s cluster. One important thing to note is that the node can be a physical computer or virtual machine.

Node Requirements
1. A kubelet running
2. Container tooling like Docker
3. A kube-proxy processing running
5. Supervisord

Recommendation
If you're using Kubernetes in production, it is typically recommended to have at least a three-node cluster.

Minikube

Lightweight Kubernetes implementation creates a VM on your local machine and deploys a simple cluster containing a single node.

Pod -The simplest unit that you can interact with. You can create, deploy, and delete pods, and it represents one running process on your cluster.

What's in the Pod?
-Your Docker application container
-Storage resources
-Unique network IP
-Options that govern how the container(s) should run

Pods Are...
-Ephemeral, disposable
-Never self-heal, and not restarted by the scheduler by itself
-Never create pods just by themselves 
-Always use higher-level constructs called controllers

Tip: use a controller like a deployment

Pod States
-Pending: where a pod has been accepted by the Kubernetes system, but a container has not been created yet
-Running: where a pod has beens scheduled on a Node
-Succeeded: all of its containers in the pod have existed with an exit status of zero in which indicates successful execution and will not be restarted
-Failed: all containers in the pod have exited and at least one container has failed and returned a non-zero exist status
-CrashLoopBackOff: container fails to start, and then Kubernetes tries over and over to restart the pod


Deployments, ReplicaSets, and Services

Benefits of Controllers
-Application reliability: multiple instances of an application running prevent problems if one or more instance fails
-Scaling: pods experience a high volume of requests, kubernetes allow you to scale up your pods allowing for a better user experience
-Load balancing: where having multiple versions of a pod running allow traffic to flow to different pods and doesn't overload one single pod or node

Kinds of Controllers
-ReplicaSets
-Deployments
-DaemonSets
-Jobs
-Services

ReplicaSet
-Ensures that a specified number of replicas for a pod are running at all times

Deployments
-A Deployment controller provides declarative updates for pods and ReplicaSets

A Deployment manages a ReplicaSet, which in turn manages a Pod. Benefits are that deployments can support a rollback mechanism.

Deployment Controller Use Cases
-Pod management: Running a ReplicaSet allows us to Deploy a number of pods, and check their status as a single unit
-Scaling a ReplicaSet scales out the pods, and allows for the deployment to handle more traffic

Deployment Controller Use Cases
Pause and Resume:
-Used with large changesets
-Pause deployment, make changes, resume deployment

Deployment Use Case
-Status
-Easy way to check the health of pods, and identify issues

Replication Controller
-Early implementation of deployment and ReplicaSet
-Use deployments and ReplicaSets instead

DaemonSets
-DaemonSets ensure that all nodes run a copy of a specified pod.
-As nodes are added or removed from the cluster, a DaemonSet will add or remove the required pods.
-Deleting a DaemonSet will clean up all the pods it created

Jobs
-Supervisor process for pods carrying our batch jobs
-Run individual processes that run once and complete successfully
-They're usually run as on cron

Service
-Allow the communication between one set of deployments with another
-Use a service to get pods in two deployments to talk to each other

Using Services
-They allow one set of pods to communicate with another set of pods in an easy way
-It's best practice to use a service when you're trying to communicate with another set of pods in an easy way
-It's best practice to use a service when you're trying to get two deployments to talk to each other so the pod in the first deployment has an IP that they can communicate with regardless of whether the pod IPs in the second deployment change

Kind of Services
-Internal: IP is only reachable within a cluster
-External: endpoint available through node ip: port (called NodePort)
-Load balancer: Exposes application to the internet with a load balancer (available with a cloud provider)

Labels, Selectors, and Namespaces

Labels: key-value pairs that are attached to an object like pods, services, and deployments. Labels are users of kubernetes to identify attributes for objects. 

Examples of Labels
"release" : "stable", "release" : "canary"
"environment" : "dev", "environment" : "qa", "environment" : "production"
"tier" : "frontend", "tier" : "backend", "tier" : "cache"

Think about what your environment looks like, and create labeling for hierarchy for it.

Labels and Selectors
-Labels used with selectors gives you a powerful feature
-Label selectors allow you to identify a set of objects

Selectors
1. Equality-based
2. Set-based

Equality-based Selectors
= -two labels or values of labels should be equal
!= -the values of labels should not be equal

Set-based Selectors
-IN: A value should be inside a set of defined values
-NOTIN: A value should not be in a set of defined values
-EXISTS: Determines whether a label exists or not

-Used with kubectl
-Examples later

Namespaces
-Feature that allow you to have multiple virtual clusters backed by the same physical cluster
-Great for large enterprises
-Allows teams to access resources, with accountability
-Great way to divide cluster resources between users
-Provides scope for names-must be unique in the namespace
-"Default" namespace created when you launch kubernetes
-Objects places in "default" namespace to start
-Newer applications install their resources in different namespace

Kubelet and kube-proxy

Kubelet: the "Kubernetes node agent" that runs on each node

Kubelet Roles
-Communicates with API server to see if pods have been assigned to nodes
-Executes pod containers via a container engine
-Mounts and runs pod volumes and secrets
-Executes health checks to identify pod/node status

Kubelet and Podspec
-Podspec: YAML file that describes a pod
-The kubelet takes a set of Podspecs that are provided by the kube-apiserver and ensures that the containers described in those Podspecs are running and healthy
-Kubelet only manages containers that were created by the API server-not any container running on the node

kube-proxy: The Network Proxy
-Proxy that runs on all worker nodes
-Reflects service as defined on each node, and can do simple network stream or round-robin forwarding across a set of backends
-Service cluster IPs and ports are currently found through Docker--link compatible environment variables specifying ports opened by the service proxy

Three Modes of kube-proxy
1. User space mode: most common mode
2. Iptables mode
3. Ipvs mode (alpha feature in v1.8)

Why These Modes are Important
-Service defined against the API server: kube-proxy watches the API server for additional and removal of services
-For each new service, kube-proxy opens a randomly chosen port on the local node
-Connections made to the chosen port are proxied to one of the corresponding back-end pods

Chapter Quiz
1) In which scenario would using namespaces be a great concept?
-In a large enterprise where there many users and teams

2) Why will you create deployments more than anything else?
-Most applications are package deployments

3) When a pod has been scheduled on a node, and all of its containers are created, which pod life cycle is represented?
-Running

4) Where do applications operate within Kubernetes?
-Worker nodes

Installing Kubernetes - Mac/Windows
Use homebrew for Mac and Scoop for Windows: docker, kubectl, minikube, and hyper-v (windows)

>minikube start --vm-driver="hyperv" --hyperv-virtual-switch="minikube"
PS C:\Users\account> minikube start --vm-driver="hyperv" --hyperv-virtual-switch="minikube"
üòÑ  minikube v1.19.0 on Microsoft Windows 10 Pro 10.0.19042 Build 19042
‚ú®  Using the hyperv driver based on user configuration
üëç  Starting control plane node minikube in cluster minikube
üî•  Creating hyperv VM (CPUs=2, Memory=4000MB, Disk=20000MB) ...
üê≥  Preparing Kubernetes v1.20.2 on Docker 20.10.4 ...
    ‚ñ™ Generating certificates and keys ...
    ‚ñ™ Booting up control plane ...
    ‚ñ™ Configuring RBAC rules ...
üîé  Verifying Kubernetes components...
    ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
üåü  Enabled addons: storage-provisioner, default-storageclass
üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default

Other Ways to Run Kubernetes

Ways to Run Kubernetes
1. Minikube
2. Docker Desktop 
3. Kubernetes in Docker (kind)
4. Managed Kubernetes service in a cloud -for example, Amazon Elastic Kubernetes Service (EKS)

Minikube
-Course is based on Minikube
-Original tooling to run Kubernetes locally
-One of the largest sub-communities in cloud native ecosystem
-Supports the latest version of Kubernetes quickly
-User experience targeted to brand-new users of Kubernetes
-Abstracts complexities while getting started
-Powerful addons features - some tooling bundled in (as we will use later)

Docker Desktop
-Easily create a Kubernetes cluster with the Docker Desktop interface
-Pleasant new user experience
-Recommend if you are having trouble with Minikube, or are already familiar with Docker Desktop
-Disadvantage
--Lags Kubernetes versions
--Can take longer to see the latest version compared to Minikube

kind
-Kubernetes in Docker
-Popular tooling
-Run kubernetes clusters in Docker containers as nodes
-Typically used for testing or Kubernetes development
-Good day-two tool
-Great for working with Kubernetes development and testing
-Not suited for beginners

Managed Kubernetes Services
-Run Kubernetes clusters without worrying about running the control plane
-Available on all major cloud providers
-If you don't already have an account with a provider, stay with Minikube
-Can spend more time getting setup than running a Kubernetes Hello World application

Quiz 3
1) If you are in Windows and using Powershell, the command docker version will check that -docker is up and running

2) What happens with the command code chmod +x ./kubectl?
-It makes the kubectl executable

3) How can you combine the deployment and service yaml into a single yaml file?
-Run the command vi helloworld-all.yml

4) How can you verify that Minikube and VirtualBox are talking to each other?
-Run the command kubectl get nodes


Quiz 4
1) Why does Kubernetes use a liveliness probe?
-So you can run a periodic check on a container to make sure the container is still healthy

2) What does running the command kubectl get pods --selector dev-lead=karthik,env=staging allow you to do?
-Add and search by multiple labels

3) How are labels added to a running pod?
-By overwriting

Quiz 5
1) Why was the Kubernetes dashboard created? 
-To visualize and monitor clusters from an operational perspective

2) Why would you use application secrets?
- When dealing with sensitive information

3) What command lets you look at the actual configmaps that you created
- kubectl get configmaps

Production Deployments of Kubernetes

Early Kubernetes Production Deployments: it was difficult/impossible to deploy and manage kubernetes to production

Kubernetes the Hard Way: check out Kelsey Hightowers "kubernetes-the-hard-way"

https://github.com/kelseyhightower/kubernetes-the-hard-way

kubeadm
Install steps

1. Initially provision the master host with Docker and the Kubernetes distrobution.
2. Run kubeadm init, which starts kubeadm, provisoins the kubernetes control plan, and provides join token.
3. Run kubeadm join with join token on each worker node. The workers will join the cluster. 

Install a Pod Network
-Evaluate your networking strategies
-Consider Flannel and Weave Net as starting possbilities

kops: used in AWS infrastructure

kops features
-Automates the K8s clsuter provisioning in AWS
-Deploys high-availability (HA) masters
-Permits upgrading with kube -up
-Uses a state-sync model for dry runs and automatic idempotency
-Generates configuration files for AWS CloudFormation and Terraform configuration
-Supports customer Kubernetes add-ons
-Uses manifest-based API configuration

kops is a very popular way to deploy Kubernetes to Amazon and looks similar to the way kubectl operates. 

If you're going to run K8s on a cloud provider, you might want to consider their native contianer services.

Managed Kubernetes vs. Self-Install
-Managed Kubernetes offerings are popular choices for Kubernetes in the cloud
-Spend less time configuring the Kubernetes Control Plane, and more time on your applications
-Caveat: limited configruation and slower version upgrades

Recommendation
-If you're running Kubernetes in the cloud, start with the managed service, it reduces infrastructure management overhead. 
-If your application require specific settings that aren't available with the managed service, then run your own Kubernetes install. 

It's quicker than you think to get a production-worthy Kubernetes platform up and running. 

Namespaces
-Way to add multi-tenancy to your Kubernetes instance. 
-Kubernetes supports multiple virtual clusters backed by the same physical cluster. These virtual clusters are called namespaces. 

Namespcae Use Cases
1. Roles and responsibilities in an enterprise
2. Partitioning landscapes: dev vs. test vs. prod
3. Customer partitioning for non-multi-tenant scenarios
4. Application partitioning 

Enterprise Roels and Responsibilities
Typically, teams operate independently but have some shared interfaces and APIs to communicate with each other.

Namespaces precent teams from confusing services and deployments that might not belong to them

Roles and Responsibilities Tips
1. Plan how you want to manage your enterprise in a K8s environment. Setting standard up front will help with long-term infrastructure management. 
2. Don't simply transpose existing on-premises control and procedures onto the new environment. This could bring your exiting infrastructure baggage to the new environment.

Dev | Test | Prod Namespaces
Namespaces partition development landscapes. 

Caution
1. Avoid really large namespaces: Do you have many applications? Consider creating additional namespaces for groups of applications. 
2. Avoid too many environments: Don't abuse namespaces resulting in unnecssary environments. 

Non-multi-tentant Customer Partitioning 
-Consulting companies and small software vendors might use this method.
-Create a namespace for each customer or project to keep them distinct -- no need to worry about reusing the same names for resources across projects.

A new side effect of using the new package member Helm, is that it has made managing K8s very complex.

Basic Namespcae Commands
-kubectl get namespaces (Returns all existing namespaces)

Basic Namespaces Commands

kubectl create namespace
-create a namespace using this command followed by the name you'd like to use

kubectl delete namespce
-delete a namespace using this command followed by the name you'd like to delete 

Basic Namespace Commands
-n namespace-name
-When deploying a resource like a deployment to a specific namespace, adding this flag will make the resource exist in the namespace. 

Monitoring and Logging

If your app isn't outputting logs, then it should.

Commands to Get Started
-stout: kubernetes will automatically link up the logs 

Once your application is running in staging or production, you might consider using a logging platform like Kibana with Elasticsearch, with logging being shipped to them from pods using Fluentd or Filebat(Logstash).

Architecture
-You would typically run a deployment for your Elasticsearch and Kibana instance outside of your application
-The Elasticsearch endpoints needs to be accessible to pods from the cluster, and the Kibana instance should be exposed as a service so that you can see log information in the Kibana user interface
-Your application deployment, you'll want the log shipper, Fluentd, Logstash or Filebeat, to gather log data and periodically send it to the Elasticsearch instance

Monitoring Priorities
-Node health
-Health of Kubernetes
-Application health (and metrics)

cAdvisor
-cAdvisor is an open-source resource usage collector that was built for containers.
-Auto-discovers all containers in the given node and collects CPU, memory, filesystem, and network usage statistics.
-Provides the overall machine usage by analyzing the root container on the machine

Prometheus
-Prometheus is an open-source system monitoring and alerting toolkit.
-Initially used to collect application metrics and monitor Kubernetes via projects like kube-prometheus

Application Metrics
-You can instrument your applications to save application monitoring data at a metrics endpoint, that Prometheus queries in a timely manner.

Promethus and cAdvisor are typically linked to Grafana, which is an open-source tool to visualize monitoring data. 

Monitoring and logging is pretty young and is rapidly changing. 
-If you're going the open-source route, read the docs for the projects
-Setting up logging and monitoring can be challenging and there's a lot of work to be done around the user experience and setup of these tools to make things easier
-There are enterprise tooling like Datadog, Splunk and Sysdig that may already be useful
-If you're already using them in your infrastructure, take a look at what kubernetes support they have and use them where applicable. No point in reinventing the wheel when you don't have to


1. Read the docs for the projects. A lot of work is being done around UX and the setup of these tools to make things easier. 
2. If you use enterprise tools like Datadog or Splunk for your infrastructure, tkae a look at what Kubernetes support they have already, and use it. 

Authentication and Authorization
-From an architecture perspective, users who are trying to access the Kubernetes API, via the kubectl command, first have to be authenticated to access the API. They then need to be authorized to run specific actions.
-Ocassionally, users may also need to have admission control to approve or rejct a request.

Two Kinds of Users
-Normal users: Humans interacting with the system
-Service accounts: Accounts managed by the K8s API

Information That Defines a User
-Username: a string to identify the end user
-UID: an idenfitier that is more consistent or unique than username
-Group: a string that associates users with a set of commonly grouped users-used later by the authorization module
-Extra fields: a map of strings that hold additional information that might be used by the authorization system

Definitions
Authenticaton
-Does a user have access to the system?

Authorization
-Can the user perform an action in the system?

Popular Authentiation Modules
-Client certs
-Static token files (static password file)
-OpenID Connect
-Webhook mode

Client Certificate Authentication
-Client certificate authentication enabled by passing --client-ca-file=FILENAME option to the API server
-Referenced file must contain one or more certificate authorities to validate client certificates
-The common name of a client certificate is used as the user name for the request

Token File Exampel
-Use --token-auth-file=FILE_WITH_TOKENS option on the command line
-Token file is a CSV file with four columns: token, user name, user UID, followed by optional group names: Example: token,user,uid,"group1,group2,group3"
-Last indefinitely and you have to restart the API server to rotate the password

OpenID Connect
-If you already have Open ID or Active Directory in your org, take a look at OpenID Connect tokens
-Scope of this feature is past the course, but look at exercise files for more details

Webhook Tokens
-The kube-apiserver calls out to a service defined by you to tell it whether a token is valid or not
-Used commonly in scenarios where you want to integrate Kubernetes with a remote authentication service

Popular Authorization Modules for Enterprises
-ABAC: Attribute-based access control: defines an access control paradign whereby access rights are granted to users through the use of policies that combines attributes together. The ABAC file defines what access a specific user might have to all resources. 
-RBAC: Role-based access control: the most common authorization mechanism used in Kubernetes and a lot of applicaitons end up using RBAC to authorize their service accounts. RBAC depends on roles and cluste roles. These are rules that represent a set of permissions. A role can be defined within the namespace with a role or clusterwide with a cluster role. 
-Webhook

Role-Based Access Control (RBAC)
-Does a user have a role that can perform a specific action?
-Lots of applications want to use RBAC-keep it turned on even if you don't use it directly

RoleBinding or ClusterRoleBinding: hold the users or groups as a reference to the role being granted. Permissions can then be granted within a namespace witha RoleBinding or cluster wide with a cluster role binding. 

Webhook Authorization Mode
-The kube-apiserver calls out to a service defined by you to tell it whether a specific action can be performed-it sends the token and the action the token is trying to perform
-This method works great when trying to integrate witha  third-party authorization system, or if you want a complex set of rules

The kube API server will send a request with a user and resource attribute data to a remote server that you define, that interprets the request and defines whether a request is allowed or not. This method works well if you're trying to integrate with a third party authorization system, or if you want a complex set of rules. 

Quiz 6

1) Starting out, why is it better for your application to be running in a pod to write logs to Stdout?
-To automatically pick up the logs, and show you anything in the log info when you do a kubectl logs command to fetch the logs

2) Who would benefit from using customer partitioning that is not multi-tenant?
-Consulting companies and small software vendors

Where to Go from here?
-Check out other container and Kubernetes courses in the library
-Kubernetes: Native Tools

Kubernetes Community
-Kubernetes the hard way: https://github.com/kelseyhightower/kubernetes-the-hard-way

Look at the K8s documentation: https://kubernetes.io/docs/home (can get confusing when looking for docs for previous version of K8s)

Slack: kubernetes.slack.com 

Cloud Native Computing Foundation: https://www.cncf.io

Meetups: https://www.meetup.com/pro/cncf

Conferences: KubeConm, DockerCon

Follow Karthik and the other admins at "theagileadmin.com"
